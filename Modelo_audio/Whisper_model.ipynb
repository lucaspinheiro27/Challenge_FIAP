{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8778651,
          "sourceType": "datasetVersion",
          "datasetId": 5276395
        }
      ],
      "dockerImageVersionId": 30734,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install setuptools-rust\n",
        "!pip install \"pymongo[srv]\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-25T04:12:15.120070Z",
          "iopub.execute_input": "2024-06-25T04:12:15.120387Z",
          "iopub.status.idle": "2024-06-25T04:12:36.565573Z",
          "shell.execute_reply.started": "2024-06-25T04:12:15.120358Z",
          "shell.execute_reply": "2024-06-25T04:12:36.564448Z"
        },
        "trusted": true,
        "id": "oK9JsqUnR0WY",
        "outputId": "1e1203f6-de12-4518-ee07-b528083b1147"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting git+https://github.com/openai/whisper.git\n  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-ih1hp7fq\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-ih1hp7fq\n  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting more-itertools\n  Downloading more_itertools-10.3.0-py3-none-any.whl (59 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m698.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/site-packages (from openai-whisper==20231117) (2.3.0)\nCollecting tiktoken\n  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/site-packages (from openai-whisper==20231117) (2.3.0)\nRequirement already satisfied: numba in /usr/local/lib/python3.10/site-packages (from openai-whisper==20231117) (0.59.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from openai-whisper==20231117) (4.66.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from openai-whisper==20231117) (1.26.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.14.0)\nRequirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /usr/local/lib/python3.10/site-packages (from numba->openai-whisper==20231117) (0.42.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2.32.3)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (1.12.1)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (12.1.105)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (10.3.2.106)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (12.1.105)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (12.1.3.1)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (2024.5.0)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (12.1.0.106)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (8.9.2.26)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (4.12.1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (12.1.105)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (11.0.2.54)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (2.20.5)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117) (12.5.40)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.6.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\nBuilding wheels for collected packages: openai-whisper\n  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802824 sha256=beb48216b28f84254a60029e897ebb015917ceee2de2f0cead0798b5c179ac8b\n  Stored in directory: /tmp/pip-ephem-wheel-cache-yvas05_1/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\nSuccessfully built openai-whisper\nInstalling collected packages: more-itertools, tiktoken, openai-whisper\nSuccessfully installed more-itertools-10.3.0 openai-whisper-20231117 tiktoken-0.7.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nCollecting setuptools-rust\n  Downloading setuptools_rust-1.9.0-py3-none-any.whl (26 kB)\nCollecting semantic-version<3,>=2.8.2\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: setuptools>=62.4 in /usr/local/lib/python3.10/site-packages (from setuptools-rust) (65.5.1)\nRequirement already satisfied: tomli>=1.2.1 in /usr/local/lib/python3.10/site-packages (from setuptools-rust) (2.0.1)\nInstalling collected packages: semantic-version, setuptools-rust\nSuccessfully installed semantic-version-2.10.0 setuptools-rust-1.9.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nCollecting pymongo[srv]\n  Downloading pymongo-4.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (669 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m669.1/669.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0\n  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: dnspython, pymongo\nSuccessfully installed dnspython-2.6.1 pymongo-4.7.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "from pymongo import MongoClient\n",
        "import whisper"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-25T04:12:36.567409Z",
          "iopub.execute_input": "2024-06-25T04:12:36.567801Z",
          "iopub.status.idle": "2024-06-25T04:12:58.822587Z",
          "shell.execute_reply.started": "2024-06-25T04:12:36.567761Z",
          "shell.execute_reply": "2024-06-25T04:12:58.821557Z"
        },
        "trusted": true,
        "id": "gsKQ412kR0Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn_str = \"mongodb+srv://user_fiaper:lu350612@cluster0.ejlmvn6.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
        "\n",
        "try:\n",
        "    client = MongoClient(conn_str)\n",
        "    print(\"Connected to MongoDB successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-25T04:12:58.823726Z",
          "iopub.execute_input": "2024-06-25T04:12:58.824120Z",
          "iopub.status.idle": "2024-06-25T04:12:58.947195Z",
          "shell.execute_reply.started": "2024-06-25T04:12:58.824090Z",
          "shell.execute_reply": "2024-06-25T04:12:58.946197Z"
        },
        "trusted": true,
        "id": "sMHcSkguR0Wk",
        "outputId": "8e490cef-b1ec-495c-d776-4ea4a4b8bd01"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Connected to MongoDB successfully!\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db = client[\"Cluster\"]\n",
        "collection = db[\"Audios\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-25T04:12:58.949080Z",
          "iopub.execute_input": "2024-06-25T04:12:58.949385Z",
          "iopub.status.idle": "2024-06-25T04:12:58.953460Z",
          "shell.execute_reply.started": "2024-06-25T04:12:58.949355Z",
          "shell.execute_reply": "2024-06-25T04:12:58.952648Z"
        },
        "trusted": true,
        "id": "mt0y7M2sR0Wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory_path = '/kaggle/input/amostra-de-dados-0/Amostra de Dados (0)'\n",
        "\n",
        "files = os.listdir(directory_path)\n",
        "\n",
        "audio_files = [file for file in files if file.endswith('.wav') or file.endswith('.mp3')]\n",
        "\n",
        "for file_name in audio_files:\n",
        "    file_path = os.path.join(directory_path, file_name)\n",
        "    try:\n",
        "\n",
        "        audio, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "\n",
        "        model = whisper.load_model(\"large\")\n",
        "        result = model.transcribe(file_path)\n",
        "\n",
        "\n",
        "        insertion_result = collection.insert_one({\n",
        "            \"file_name\": file_name,\n",
        "            \"transcription\": result[\"text\"]\n",
        "        })\n",
        "\n",
        "\n",
        "        print(f\"Inserted transcription for {file_name} with ID: {insertion_result.inserted_id}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_name}: {str(e)}\")\n",
        "\n",
        "\n",
        "client.close()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-25T04:12:58.954544Z",
          "iopub.execute_input": "2024-06-25T04:12:58.954796Z",
          "iopub.status.idle": "2024-06-25T04:21:20.504388Z",
          "shell.execute_reply.started": "2024-06-25T04:12:58.954769Z",
          "shell.execute_reply": "2024-06-25T04:21:20.503173Z"
        },
        "trusted": true,
        "id": "7xH5FY-2R0Wn",
        "outputId": "61a70534-2b34-4cbb-ead5-1aba41ba79a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████████████████████████████████| 2.88G/2.88G [00:21<00:00, 146MiB/s]\n/usr/local/lib/python3.10/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Inserted transcription for 2968253.wav with ID: 667a4494eccb0338d71ac131\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Inserted transcription for 2968468.wav with ID: 667a45c0eccb0338d71ac132\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}